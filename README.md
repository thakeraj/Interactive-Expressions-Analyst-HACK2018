What it does:
1. Record/Upload your video speaking(for some occasion like say debate, interview or funeral).
2. IEA will analyze your expressions and vocal tone describing you on how are you are being perceived by others.
3. The recommendation model drives you to the YouTube link to improve the aspect of expressing.
4. You Live & Learn! :)

How we built it:
1. Front End: HTML/CSS, Javascript, Bootstrap, High charts
2. Backend: C#, Microsoft Cognitive Services API (Video Indexer API, Face API), Google-YouTube recommendations API hosted on Microsft Azure.
3. AGILE!

Challenges we ran into:

We had to Analyze the video emotions frame by frame since there was no API to analyze the tone of the video as a whole.

Accomplishments that we're proud of:

4 People with no common background, brainstorming and delivering a working model in a limited timeframe was challenging but fun!

What we learned:

Microsoft Azure Cloud Services, Cognitive Services APIs.

What's next for IEA:

Personalized Training Module for Training self in a particular expression domain.
